\chapter{Nonparametric Statistics}

\section{Probability Distribution}

\subsection{Cumulative Distribution Function}

Let $X_{1},\ldots,X_{n}\sim F$ where $F(x)=\mathbb{P}(X\leq x)$ is a distribution function on the real line.

\begin{definition}[Empirical Cumulative Distribution Function]
	The empirical cumulative distribution function $\widehat{F}_{n}$ is the CDF that puts mass $1/n$ at each data point $X_{i}$, that,
	\begin{equation}
		\widehat{F}_{n}(x)=\frac{1}{n}\sum_{i=1}^{n}I\left(X_{i}\leq x\right)
	\end{equation}
\end{definition}

\subsection{Probability Density Function}

\subsubsection{Histogram}

\subsubsection{Kernel Density Estimation}

\section{Kernel Methods}

\subsection{Positive Definite Kernels}

\begin{definition}[Positive Definite Kernel]
	Let $\mcX$ be a set, a function $K:\mcX\times\mcX\rightarrow\bbR$ is called a positive definite kernel on $\mcX$ if and only if it is
	\begin{enumerate}
		\item symmetric, that is,
		      \begin{equation}
			      K\left(\bfx,\bfx^{\prime}\right)=K\left(\bfx^{\prime},\bfx\right),\quad\forall\bfx,\bfx^{\prime}\in\mcX
		      \end{equation}
		\item positive definite, that is,
		      \begin{equation}
			      \sum_{i=1}^{n}\sum_{j=1}^{n}c_{i}c_{j}K\left(\bfx_{i},\bfx_{j}\right)\geq 0,
		      \end{equation}
		      holds for any $x_{1},\ldots,x_{n}\in\mcX$, given $n\in\mathbb{N},c_{1},\ldots,c_{n}\in\bbR$.
	\end{enumerate}
\end{definition}

\subsubsection{Construction of the Reproducing Kernel Hilbert Space}

\begin{theorem}[Morse-Aronszajn's Theorem] \label{thm:morse-aronszajn}
	For any set $\mcX$, suppose $K:\mcX\times\mcX\rightarrow\bbR$ is positive definite, then there is a unique RKHS $\mathcal{H}\subset\bbR^{\mcX}$ with reproducing kernel $K$.
\end{theorem}

\begin{proof}
	\begin{enumerate}
		\item How to build a valid pre-RKHS $\mathcal{H}_{0}$?

		      Consider the vector space $\mathcal{H}_{0}\subset\mathcal{R}^{\mcX}$ spanned by the functions $\left\{K\left(\cdot,\bfx\right)\right\}_{\bfx\in\mcX}$. For any $f,g\in\mathcal{H}_{0}$, suppose
		      \begin{equation*}
			      f=\sum_{i=1}^{m}a_{i}K\left(\cdot,\bfx_{i}\right),\quad g=\sum_{j=1}^{n}b_{j}K\left(\cdot,\mathbf{y}_{j}\right)
		      \end{equation*}
		      and let the inner product of $\mathcal{H}_{0}$ be
		      \begin{equation}
			      \left\langle f,g\right\rangle=\sum_{i=1}^{m}\sum_{j=1}^{n}a_{i}b_{j}K\left(\bfx_{i},\mathbf{y}_{j}\right)
			      \label{eq:definition-pre-rkhs-inner-product}
		      \end{equation}

		      Let $\bfx\in\mcX$,
		      \begin{equation*}
			      \left\langle f,K\left(\cdot,\bfx\right)\right\rangle_{\mathcal{H}_{0}}=\sum_{i=1}^{m}a_{i} K\left(\bfx,\bfx_{i}\right)=f(\bfx)
			      \label{eq:reproducing-kernel}
		      \end{equation*}

		      And, we also have
		      \begin{equation*}
			      \langle f, g\rangle_{\mathcal{H}_{0}}=\sum_{i=1}^{m} a_{i} g\left(\bfx_{i}\right)=\sum_{j=1}^{n} b_{j} f\left(\mathbf{y}_{j}\right)
		      \end{equation*}

		      Suppose
		      \begin{equation*}
			      f=\sum_{i=1}^{m}a_{i}K\left(\cdot,\bfx_{i}\right),\quad g=\sum_{j=1}^{n}b_{j}K\left(\cdot,\mathbf{y}_{j}\right),\quad h=\sum_{k=1}^{p}c_{k}K\left(\cdot,\mathbf{z}_{k}\right)
		      \end{equation*}
		      \begin{enumerate}
			      \item Linearity: For any $\alpha,\beta\in\bbR$, $\left\langle\alpha f+\beta g,h\right\rangle_{\mathcal{H}_{0}}=\alpha\left\langle f,h\right\rangle_{\mathcal{H}_{0}}+\beta\left\langle g,h\right\rangle_{\mathcal{H}_{0}}$.
			            \begin{equation*}
				            \begin{aligned}
					            \left\langle\alpha f+\beta g,h\right\rangle_{\mathcal{H}_{0}}= & \left[\alpha\sum_{i=1}^{m}a_{i}K\left(\cdot,\bfx_{i}\right)+\beta\sum_{j=1}^{n}b_{j}K\left(\cdot,\mathbf{y}_{j}\right)\right]\cdot\sum_{k=1}^{p}c_{k}K\left(\cdot,\mathbf{z}_{k}\right) \\
					            =                                                              & \alpha\sum_{i=1}^{m}\sum_{k=1}^{p}a_{i}c_{k}K\left(\bfx_{i},\mathbf{z}_{k}\right)+\beta\sum_{j=1}^{n}\sum_{k=1}^{p}b_{j}c_{k}K\left(\mathbf{y}_{j},\mathbf{z}_{k}\right)                \\
					            =                                                              & \alpha\left\langle f,h\right\rangle_{\mathcal{H}_{0}}+\beta\left\langle g,h\right\rangle_{\mathcal{H}_{0}}
				            \end{aligned}
			            \end{equation*}
			      \item Conjugate Symmetry: $\langle f,g\rangle_{\mathcal{H}_{0}}=\langle g,f\rangle_{\mathcal{H}_{0}}$.
			            \begin{equation*}
				            \begin{aligned}
					            \langle f,g\rangle_{\mathcal{H}_{0}}= & \sum_{i=1}^{m}\sum_{j=1}^{n}a_{i}b_{j}K\left(\bfx_{i},\mathbf{y}_{j}\right)=\sum_{j=1}^{n}\sum_{i=1}^{m}b_{j}a_{i}K\left(\mathbf{y}_{j},\bfx_{i}\right) \\
					            =                                     & \langle g,f\rangle_{\mathcal{H}_{0}}
				            \end{aligned}
			            \end{equation*}
			      \item Positive Definiteness: $\langle f,f\rangle_{\mathcal{H}_{0}}\geq 0$ and $\langle f,f\rangle_{\mathcal{H}_{0}}=0$ if and only if $f=0$.

			            By positive definiteness of $K$, we have:
			            \begin{equation*}
				            \langle f,f\rangle_{\mathcal{H}_{0}}=\|f\|_{\mathcal{H}_{0}}^{2}=\sum_{i=1}^{m}\sum_{j=1}^{m}a_{i}a_{j}K\left(\bfx_{i},\bfx_{j}\right)\geq 0
			            \end{equation*}

			            As for, $\langle f,f\rangle_{\mathcal{H}_{0}}=0$ if and only if $f=0$, we have,
			            \begin{itemize}
				            \item["$\Rightarrow$"] If $f=0$, that is $f=\sum_{i=1}^{m}a_{i}K\left(\cdot,\bfx_{i}\right)=0$, we have
					            \begin{equation*}
						            \langle f,f\rangle_{\mathcal{H}_{0}}=\sum_{i=1}^{m}a_{i}f=0
					            \end{equation*}
				            \item["$\Leftarrow$"] For $\forall\bfx\in\mcX$, by Cauchy-Schwarz Inequality, we have,
					            \begin{equation*}
						            |f(\bfx)|=\left|\left\langle f,K\left(,\cdot{\bfx}\right)\right\rangle_{\mathcal{H}_{0}}\right|\leq\|f\|_{\mathcal{H}_{0}}\cdot K\left(\bfx,\bfx\right)^{\frac{1}{2}}
					            \end{equation*}
					            therefore, if $\|f\|_{\mathcal{H}_{0}}=0$, then $f=0$
			            \end{itemize}
		      \end{enumerate}
		      Hence, the definition in equation \eqref{eq:definition-pre-rkhs-inner-product} is a valid inner product, which is a valid pre-RKHS $\mathcal{H}_{0}$.
	\end{enumerate}
\end{proof}

\subsubsection{Examples of Kernels}

\begin{example}[Gaussian Kernel]
	\begin{equation}
		K(\bfx,\mathbf{y})=\exp\left(-\frac{\left\|\bfx-\mathbf{y}\right\|^{2}}{2\sigma^{2}}\right),\quad\bfx,\mathbf{y}\in\bbR^{d}
	\end{equation}
\end{example}

\begin{proof}
	\begin{enumerate}
		\item It is obvious that $K(\bfx,\mathbf{y})$ is symmetric, we only need to show $K(\bfx,\mathbf{y})$ is positive definite.
		      \begin{equation*}
			      \begin{aligned}
				      K(\bfx,\mathbf{y})= & \exp\left(-\frac{\left\|\bfx-\mathbf{y}\right\|^{2}}{2\sigma^{2}}\right)                                                                                                                            \\
				      =                   & \exp\left(-\frac{1}{2\sigma^{2}}\|\bfx\|^{2}\right)\cdot\exp\left(\frac{1}{\sigma^{2}}\left\langle\bfx,\mathbf{y}\right\rangle\right)\cdot\exp\left(-\frac{1}{2\sigma^{2}}\|\mathbf{y}\|^{2}\right)
			      \end{aligned}
		      \end{equation*}

		      By the Taylor expansion of the exponential function, that
		      \begin{equation*}
			      \exp\left(\frac{x}{\sigma^{2}}\right)=\sum_{n=0}^{+\infty}\left\{\frac{x^{n}}{\sigma^{2n}\cdot n!}\right\}
		      \end{equation*}
		      Hence,
		      \begin{equation*}
			      \exp\left(\frac{1}{\sigma^{2}}\left\langle\bfx,\mathbf{y}\right\rangle\right)=\sum_{n=0}^{+\infty}\left\{\frac{\left\langle\bfx,\mathbf{y}\right\rangle^{n}}{\sigma^{2n}\cdot n!}\right\}
		      \end{equation*}

		      By the Multinomial Theorem, we have
		      \begin{equation*}
			      \begin{aligned}
				      \left\langle\bfx,\mathbf{y}\right\rangle^{n}= & \left(\sum_{i=1}^{d}x_{i}y_{i}\right)^{n}=\sum_{k_{1}+k_{2}+\ldots+k_{d}=n}\left[\binom{n}{k_{1},k_{2},\ldots,k_{d}}\prod_{i=1}^{d}\left(x_{i}y_{i}\right)^{k_{i}}\right]                                     \\
				      =                                             & \sum_{k_{1}+k_{2}+\ldots+k_{d}=n}\left[\binom{n}{k_{1},k_{2},\ldots,k_{d}}^{\frac{1}{2}}\prod_{i=1}^{d}x_{i}^{k_{i}}\cdot\binom{n}{k_{1},k_{2},\ldots,k_{d}}^{\frac{1}{2}}\prod_{i=1}^{d}y_{i}^{k_{i}}\right] \\
			      \end{aligned}
		      \end{equation*}
		      Therefore,
		      \begin{equation*}
			      \begin{aligned}
				      K(\bfx,\mathbf{y})= & \exp\left(-\frac{\left\|\bfx-\mathbf{y}\right\|^{2}}{2\sigma^{2}}\right)=\exp\left(-\frac{\|\bfx\|^{2}}{2\sigma^{2}}\right)\cdot\exp\left(-\frac{\|\mathbf{y}\|^{2}}{2\sigma^{2}}\right)\cdot\sum_{n=0}^{+\infty}\left\{\frac{\left\langle\bfx,\mathbf{y}\right\rangle^{n}}{\sigma^{2n}\cdot n!}\right\} \\
				      =                   & \sum_{n=0}^{+\infty}\frac{\exp\left(-\frac{\|\bfx\|^{2}}{2\sigma^{2}}\right)}{\sigma^{n}\cdot\sqrt{n!}}\cdot\frac{\exp\left(-\frac{\|\mathbf{y}\|^{2}}{2\sigma^{2}}\right)}{\sigma^{n}\cdot\sqrt{n!}}\cdot\left\langle\bfx,\mathbf{y}\right\rangle^{n}
			      \end{aligned}
		      \end{equation*}

		      Let
		      \begin{equation*}
			      c_{\sigma,n}\left(\bfx\right)=\frac{\exp\left(-\frac{\|\bfx\|^{2}}{2\sigma^{2}}\right)}{\sigma^{n}\cdot\sqrt{n!}},\quad f_{n,\mathbf{k}}\left(\bfx\right)=\binom{n}{k_{1},k_{2},\ldots,k_{d}}^{\frac{1}{2}}\prod_{i=1}^{d}x_{i}^{k_{i}}
		      \end{equation*}
		      then,
		      \begin{equation*}
			      \begin{aligned}
				      K(\bfx,\mathbf{y})= & \sum_{n=0}^{+\infty}\sum_{k_{1}+k_{2}+\ldots+k_{d}=n}c_{\sigma,n}\left(\bfx\right)f_{n,\mathbf{k}}\left(\bfx\right)\cdot c_{\sigma,n}\left(\mathbf{y}\right)f_{n,\mathbf{k}}\left(\mathbf{y}\right) \\
				      =                   & \left\langle\Phi\left(\bfx\right),\Phi\left(\mathbf{y}\right)\right\rangle                                                                                                                          \\
			      \end{aligned}
		      \end{equation*}
		      where $\Phi\left(\bfx\right)_{\sigma,n,\mathbf{k}}=c_{\sigma,n}\left(\bfx\right)f_{n,\mathbf{k}}\left(\bfx\right)$.

		      \begin{equation*}
			      \begin{aligned}
				      \sum_{i=1}^{n}\sum_{j=1}^{n}c_{i}c_{j}K\left(\bfx_{i},\bfx_{j}\right)= & \sum_{i=1}^{n}\sum_{j=1}^{n}c_{i}c_{j}\left\langle\Phi\left(\bfx_{i}\right),\Phi\left(\bfx_{j}\right)\right\rangle       \\
				      =                                                                      & \left\langle\sum_{i=1}^{n}c_{i}\Phi\left(\bfx_{i}\right),\sum_{i=1}^{n}c_{i}\Phi\left(\bfx_{i}\right)\right\rangle\geq 0
			      \end{aligned}
		      \end{equation*}
		      for any $x_{1},\ldots,x_{n}\in\mcX$, given $n\in\mathbb{N},c_{1},\ldots,c_{n}\in\bbR$, i.e., $K(\bfx,\mathbf{y})$ is positive definite.
	\end{enumerate}
\end{proof}
